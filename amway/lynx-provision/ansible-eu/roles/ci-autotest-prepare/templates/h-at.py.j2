#!/usr/bin/env python
# -*- coding: utf-8 -*-
import argparse
import re
import os
import subprocess
import junit_xml_output
import datetime
import shlex
import sys
import traceback
import threading

red_color_bold = "\033[1;31m"
red_color = "\033[0;31m"
no_color = '\033[0m'
green_color = "\033[0;32m"
blue_color = "\033[0;36m"
magenta_color = "\033[0;35m"
cyan_color = "\033[0;36m"
brown_color = "\033[0;33m"


def h_mvn_test(run_target, test_dir, test_class, test_method, report_name, template, calculate):
    print (run_target.__str__())
    h_mvn_run = subprocess.Popen(' '.join(run_target), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True)
    log_out = []
    print("Exit code: ", h_mvn_run.returncode)
    h_mvn_data = h_mvn_run.communicate()
    for line in h_mvn_data[0].rstrip().decode('cp1252', "ignore").split('\n'):
        if line:
            print(line)
            log_out.append(line)
    if h_mvn_run.returncode != 0:
        exit(h_mvn_run.returncode)
    h_logparce(log_out, template, test_class, test_method, report_name, calculate)

def create_file(file_name, message):
    target = open(file_name, "w")
    target.write(message)
    target.close()


def h_logparce(src_logfile, template, test_class, test_method, report_name, calculate):
    #    test_cases = []
    h_errors = []
    test_coverage = 0
    for log_lines in src_logfile:
        cut_log_lines = log_lines.__str__().replace('\n', ' ').replace('\r', ' ').replace('\t', ' ').replace('',' ') \
            .replace('?', ' ').replace('?[32', ' ').replace('[31m', '').replace('[36m', '').replace('[32m', '') \
            .replace('[0m','').replace('←', ' ')
        results = re.search(template, cut_log_lines)
        if results:
            h_errors.append(results.group(0))
        result = re.search('(.*)BUILD\ FAILURE(.*)', cut_log_lines)
        if results:
            h_errors.append(results.group(0))

    if h_errors:
        print(brown_color + "Summary of captured expressions:" + no_color)
        results_scenarios_count = 0
        results_failed_count = 0
        results_passed_count = 0
        for a in h_errors:
            print(red_color + a.__str__() + no_color)
            if calculate == 0:
                temp_scenarios = '(.*) Scenarios \( (.*)'
                results_scenarios = re.search(temp_scenarios, a.__str__()).group(1).strip()  # Test count
                string_statuses_result = re.search(temp_scenarios, a.__str__()).group(2).strip()

                temp_failed = '(.*) failed (.*)'
                results_failed = re.search(temp_failed, string_statuses_result.__str__())
                if results_failed.__str__() == "None":
                    results_failed = "0"
                else:
                    string_statuses_result = results_failed.group(2).strip()
                    results_failed = results_failed.group(1).strip()

                temp_failed = '(.*)BUILD\ FAILURE(.*)'
                results_failed = re.search(temp_failed, string_statuses_result.__str__())
                if results_failed.__str__() == "None":
                    results_failed = "0"
                else:
                    string_statuses_result = results_failed.group(2).strip()
                    results_failed = results_failed.group(1).strip()

                temp_passed = '(.*)passed \)'
                results_passed = re.search(temp_passed, string_statuses_result.__str__())
                if results_passed.__str__() == "None":
                    results_passed = "0"
                else:
                    results_passed = re.findall("\d+", string_statuses_result.__str__())[0].__str__()

                results_scenarios_count = int(results_scenarios_count) + int(results_scenarios)
                results_failed_count = int(results_failed_count) + int(results_failed)
                results_passed_count = int(results_passed_count) + int(results_passed)

        print (brown_color)
        print("Number of rows caught in the log: ", len(h_errors))
        print (no_color)
        if calculate == 0:
            print (red_color_bold + results_scenarios_count.__str__() + " Scenarios ( " + results_failed_count.__str__()
                   + " failed , " + results_passed_count.__str__() + " passed )" + no_color)
            if(int(results_scenarios_count) != 0):
                test_coverage = (float(results_failed_count)/float(results_scenarios_count)).__float__()*100
                print(red_color_bold + "% of Test failed: " + no_color + red_color + "%.2f" % test_coverage + no_color)
            else:
                print (red_color_bold + "0 Scenarios was run. Failed to run." + no_color)
                sys.exit(1)

    #        test_cases.append(junit_xml_output.TestCase(test_method, "\n".join(h_errors[1:]), "failure"))
    #        junit_xml = junit_xml_output.JunitXml(test_class, test_cases)
    else:
        print("No expressions found")
    #        test_cases.append(junit_xml_output.TestCase(test_method, "successfully done", "successful"))
    #        junit_xml = junit_xml_output.JunitXml(test_class, test_cases)
    #    path = "test-reports"
    #    file_name = path + "/" + report_name + "-" + datetime.datetime.now().strftime("%Y-%m-%d-%H-%M-%S") + ".xml"
    #    if not os.path.exists(path):
    #        print("Creating directory " + path)
    #        os.makedirs(path)
    #    print("Writing " + file_name)
    #    target = open(file_name, "w")
    #    target.write(junit_xml.dump())
    #    target.close()

    print("Write marker if failed")
    if h_errors and (calculate == 1 or test_coverage > 0):
        create_file('.failed', 'FAILED')
        print("FAILED")
        print(threading.enumerate())
        sys.exit(1)
    print("PASSED")
    print(threading.enumerate())

if __name__ == "__main__":
    # read regex rules
    error_list = '(.*)BUILD\ FAILURE(.*)'
    error_list_AQA = '(.*) Scenarios (.*)\( (.*) \)'
    mvn_bin_dir = r'/usr/local/src/apache-maven/bin/'
    print(os.getcwd())
    parser = argparse.ArgumentParser()
    parser.add_argument('--file', action='store', dest='log_name', help='Parse stored file')
    parser.add_argument('--mvn', action='store_true', dest='run_mvn', help='Run mvn')
    parser.add_argument('--rest-type', action='store', dest='s_rest', help='mvn : Type test is a REST')
    parser.add_argument('--mvn-env', action='store', dest='s_env', help='mvn : Environment name')
    parser.add_argument('--mvn-country', action='store', dest='s_country', help='mvn : Country to test')
    parser.add_argument('--mvn-useGrid', action='store', dest='s_useGrid', help='mvn : Boolean - use grid or not')
    parser.add_argument('--mvn-browser', action='store', dest='s_browser', help='mvn : Browse name')
    parser.add_argument('--mvn-cucumber-options', action='store', dest='s_cucumber_options',
                        help='mvn : Cucumber options')
    parser.add_argument('--mvn_test', action='store', dest='s_mvn_test', help='mvn : Cucumber options')

    args = parser.parse_args()
    if args.log_name:
        logfile = open(args.log_name, "r")
        h_logparce(logfile.readlines(), error_list, "local file test", "Local file", "local")
    if args.run_mvn:
        if args.s_rest:
            h_mvn_test(['mvn', 'clean', 'test', '-P ' + args.s_rest],
                       mvn_bin_dir,
                       "Autotest result analise",
                       "See result in Bamboo artifacts tab",
                       "Maven",
                       error_list, 1)
        else:
            # Is not used the current options instead of this it's better to use 's_mvn_test'
            # -Denv=fqa1 -Dcountry=sweden -DuseGrid=false -Dbrowser=chrome -Dcucumber.options="--tags ~@Wip --tags @Regression"
            h_mvn_test(['mvn', 'clean', 'test',
                        '-Denv=' + args.s_env,
                        '-Dcountry' + args.s_country,
                        '-DuseGrid' + args.s_useGrid,
                        '-Dbrowser=' + args.s_browser,
                        '-Dcucumber.options=\"' + args.s_cucumber_options + '\"'
                        ],
                       mvn_bin_dir,
                       "Autotest result analise",
                       "See result in Bamboo artifacts tab",
                       "Maven",
                       error_list_AQA, 0)
    if args.s_mvn_test:
        cmd = args.s_mvn_test
        args1 = shlex.split(cmd)
        h_mvn_test(args1,
                   mvn_bin_dir,
                   "Autotest result analise",
                   "See result in Bamboo artifacts tab",
                   "Maven",
                   error_list_AQA, 0)
