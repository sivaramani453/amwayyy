name: Daily FQA EU Regression Finland

on:
  workflow_dispatch:

  schedule:
    - cron: 0 1 * * 1-5

env:
  ECR_REGISTRY: "744058822102.dkr.ecr.eu-central-1.amazonaws.com"
  DOCKER_CONFIG: "/home/github/.docker"
  # Tests related vars
  BROWSER: chrome
  COUNTRY: finland
  ENV: ultraserve_fqa
  TEST_RUN_ID: ""
  ARTIFACTS_DIR: b2c_ootb/target/allure-results
  REPORT_DIR: amway-test-system-ui-tests/target/site/allure-maven-plugin
  REPORT_HISTORY_DIR: amway-test-system-ui-tests/target/site/allure-maven-plugin/history
  HISTORY_FILTER: "AllureReportsHistoryFilter"

  # Reports related vars
  S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME}}
  REPORT_URL: "https://allure-reports.hybris.eu.eia.amway.net"
  CONFIG: "config"
  API_GATEWAY: "api_gateway"
  BOSS_INTEGRATION: "boss_integration"
  SMOKE: "smoke"
  REGRESSION: "regression"

  # actions related vars
  ACTIONS_REPO: AmwayCommon/actions

  # Notifications related vars
  SMTP_SERVER: relay.hybris.eu.eia.amway.net
  RCPTS: Amway.EU.AQA@Amway.com
  ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true
jobs:
  regression_history:
    name: Regression history cleaning (t3a.medium)
    runs-on: [ self-hosted, t3a.medium ]
    timeout-minutes: 180
    if: ${{ always() }}

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"
          HISTORY_DIR="./history"
          S3_HISTORY_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/history/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV
          echo "HISTORY_DIR=$HISTORY_DIR" >> $GITHUB_ENV
          echo "S3_HISTORY_URL=$S3_HISTORY_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Checkout ${{ env.ACTIONS_REPO }} repo
        uses: actions/checkout@v4
        with:
          path: actions
          token: ${{ secrets.GIT_TOKEN }}
          repository: ${{ env.ACTIONS_REPO }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}

      - name: Check and copy previously-saved history folder to project dir
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          mkdir $HISTORY_DIR
          aws s3 cp --recursive $S3_HISTORY_URL $HISTORY_DIR
          if [ -z "$(ls -A $HISTORY_DIR)"]; then
            echo there is NO history FOUND for this workflow
          else
            echo this workflow history is copied from $S3_HISTORY_URL
          fi

      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn -e clean install -Dbrowser=$BROWSER \
                               -DfailIfNoTests=$FAIL_IF_NO_TESTS \
                               -PdataGenerator \
                               -Dcountry=$COUNTRY \
                               -Denv=$ENV \
                               -Dtest=$HISTORY_FILTER

      - name: Try to upload filtered history back to s3
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -z "$(ls -A $HISTORY_DIR)"]; then
              echo History dir of report NOT FOUND
              echo "HISTORY_UPLOADED=no" >> $GITHUB_ENV
              exit 0
          else
              echo Going to upload filtered history to s3
              aws s3 cp --quiet --recursive $HISTORY_DIR $S3_HISTORY_URL
              echo "HISTORY_UPLOADED=yes" >> $GITHUB_ENV
              echo History was uploaded
          fi

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  config:
    name: Run config tests for RI 1-4 (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]

    env:
      TEST: configSmoke
      TAGS: "@Config and (@ri1 or @ri2 or @ri3 or @ri4)"
      CYCLE: "AMWEIA-C18605"

    outputs:
      allure_addr: ${{ steps.summary.outputs.url }}
      passrate: ${{ steps.stats.outputs.passrate }}

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"
          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$CONFIG"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Checkout ${{ env.ACTIONS_REPO }} repo
        uses: actions/checkout@v4
        with:
          path: actions
          token: ${{ secrets.GIT_TOKEN }}
          repository: ${{ env.ACTIONS_REPO }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}

      - name: Maven execution
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -P$TEST \
          -Denv=$ENV \
          -Dbrowser=$BROWSER \
          -Dcountry=$COUNTRY \
          -DtestRunId=$TEST_RUN_ID \
          -Dcycle=$CYCLE \
          -Dcucumber.filter.tags="$TAGS"

      - name: Generate allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn -B allure:report

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              echo Going to upload report to s3
              aws s3 cp --quiet --recursive $REPORT_DIR $S3_FULL_URL
              echo "ARTIFACT_UPLOADED=yes" >> $GITHUB_ENV
              echo Report was uploaded
          else
              echo Reports dir NOT FOUND
              echo "ARTIFACT_UPLOADED=no" >> $GITHUB_ENV
              exit 0
          fi

      - name: Summary
        if: ${{ always() }}
        id: summary
        shell: bash
        run: |
          if [ $ARTIFACT_UPLOADED != 'yes' ]; then
              echo "Allure report was not uploaded"
              echo "Please check logs of previous steps"
          else
            echo "Allure report is ready --> $REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$CONFIG/"
            echo "url=$REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$CONFIG/" >> $GITHUB_OUTPUT
          fi

      - name: Extract stats for email
        id: stats
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              TEST_STATS=$( jq '.statistic' $REPORT_DIR/widgets/summary.json )
              echo Extracted test stats
              echo "${TEST_STATS}"
              PASSED=$( jq '.statistic.passed' $REPORT_DIR/widgets/summary.json )
              echo "${PASSED}"     
              TOTAL=$( jq '.statistic.total' $REPORT_DIR/widgets/summary.json )
              echo "${TOTAL}"          
              PASSRATE=$(awk -v p=$PASSED -v t=$TOTAL 'BEGIN {r=p/t*100; printf "%.2f", r}')
              echo "passrate=$PASSRATE" >> $GITHUB_OUTPUT  
          else
              exit 0
          fi

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  api_gateway:
    name: API Gateway Endpoints run (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180

    env:
      TEST: singleThread
      CYCLE: "AMWEIA-C18603"

    outputs:
      allure_addr: ${{ steps.summary.outputs.url }}
      passrate: ${{ steps.stats.outputs.passrate }}

    steps:
      - name: Print command
        shell: bash
        run: |
          echo "Going to run @ApiGateway for $COUNTRY"

      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$API_GATEWAY"
          S3_HISTORY_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/history/$API_GATEWAY"
          HISTORY_DIR="./history"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV
          echo "S3_HISTORY_URL=$S3_HISTORY_URL" >> $GITHUB_ENV
          echo "HISTORY_DIR=$HISTORY_DIR" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}

      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -P$TEST \
          -Denv=$ENV \
          -Dcountry=$COUNTRY \
          -Dbrowser=$BROWSER \
          -DtestRunId=$TEST_RUN_ID \
          -Dcycle=$CYCLE \
          -Dcucumber.filter.tags="@ApiGateway and (@$COUNTRY or @ri1)"

      - name: Copy and filter previously saved history folder to allure results
        if: ${{ always() }}
        working-directory: ${{ env.CODEBASE }}
        shell: bash
        run: |
          mkdir -p $HISTORY_DIR
          aws s3 cp --recursive $S3_HISTORY_URL $HISTORY_DIR
          if [ -z "$(ls -A $HISTORY_DIR)"]; then
            echo "No history found for this workflow"
          else
            mvn -e clean install -Dbrowser="$BROWSER" \
                                 -DfailIfNoTests=false \
                                 -PdataGenerator \
                                 -Dcountry="$COUNTRY" \
                                 -Denv="$ENV" \
                                 -Dtest="$HISTORY_FILTER"
            cp -r "$HISTORY_DIR" "$ARTIFACTS_DIR/history"
          fi

      - name: Generate allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn -B allure:report

      - name: Try to upload history of allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d "$REPORT_HISTORY_DIR" ]; then
            echo "Going to upload report history to s3"
            aws s3 cp --quiet --recursive $REPORT_HISTORY_DIR $S3_HISTORY_URL
            echo "HISTORY_UPLOADED=yes" >> $GITHUB_ENV
            echo "History uploaded"
          else
            echo "History folder of report is not found"
            REPORT_DIR_STRUCT=$(ls -lah $REPORT_DIR)
            echo "Report directory structure: $REPORT_DIR_STRUCT"
            echo "HISTORY_UPLOADED=no" >> $GITHUB_ENV
            exit 0
          fi

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              echo Going to upload report to s3
              aws s3 cp --quiet --recursive $REPORT_DIR $S3_FULL_URL
              echo "ARTIFACT_UPLOADED=yes" >> $GITHUB_ENV
              echo Report was uploaded
          else
              echo Reports dir NOT FOUND
              echo "ARTIFACT_UPLOADED=no" >> $GITHUB_ENV
              exit 0
          fi

      - name: Summary
        if: ${{ always() }}
        id: summary
        shell: bash
        run: |
          if [ $ARTIFACT_UPLOADED != 'yes' ]; then
              echo "Allure report was not uploaded"
              echo "Please check logs of previous steps"
          else
            echo "Allure report is ready --> $REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$API_GATEWAY/"
            echo "url=$REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$API_GATEWAY/" >> $GITHUB_OUTPUT
          fi

      - name: Extract stats for email
        id: stats
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              TEST_STATS=$( jq '.statistic' $REPORT_DIR/widgets/summary.json )
              echo Extracted test stats
              echo "${TEST_STATS}"
              PASSED=$( jq '.statistic.passed' $REPORT_DIR/widgets/summary.json )
              echo "${PASSED}"     
              TOTAL=$( jq '.statistic.total' $REPORT_DIR/widgets/summary.json )
              echo "${TOTAL}"          
              PASSRATE=$(awk -v p=$PASSED -v t=$TOTAL 'BEGIN {r=p/t*100; printf "%.2f", r}')
              echo "passrate=$PASSRATE" >> $GITHUB_OUTPUT  
          else
              exit 0
          fi

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  boss_integration:
    name: BOSS Integration Endpoints run (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180

    env:
      CYCLE: "AMWEIA-C18604"
      TEST: singleThread
      EXCLUDE_TEST: "@excluded"

    outputs:
      allure_addr: ${{ steps.summary.outputs.url }}
      passrate: ${{ steps.stats.outputs.passrate }}

    steps:
      - name: Print command
        shell: bash
        run: |
          echo "Going to run @BossIntegration for $COUNTRY"

      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$BOSS_INTEGRATION"
          S3_HISTORY_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/history/$BOSS_INTEGRATION"
          HISTORY_DIR="./history"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV
          echo "S3_HISTORY_URL=$S3_HISTORY_URL" >> $GITHUB_ENV
          echo "HISTORY_DIR=$HISTORY_DIR" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -P$TEST \
                            -Denv=$ENV \
                            -Dcountry=$COUNTRY \
                            -Dbrowser=$BROWSER \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="@BossIntegration and (@$COUNTRY or @ri1) and not @$EXCLUDE_TEST"

      - name: Copy and filter previously saved history folder to allure results
        if: ${{ always() }}
        working-directory: ${{ env.CODEBASE }}
        shell: bash
        run: |
          mkdir -p $HISTORY_DIR
          aws s3 cp --recursive $S3_HISTORY_URL $HISTORY_DIR
          if [ -z "$(ls -A $HISTORY_DIR)"]; then
            echo "No history found for this workflow"
          else
            mvn -e clean install -Dbrowser="$BROWSER" \
                                 -DfailIfNoTests=false \
                                 -PdataGenerator \
                                 -Dcountry="$COUNTRY" \
                                 -Denv="$ENV" \
                                 -Dtest="$HISTORY_FILTER"
            cp -r "$HISTORY_DIR" "$ARTIFACTS_DIR/history"
          fi

      - name: Generate allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn allure:report

      - name: Try to upload history of allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d "$REPORT_HISTORY_DIR" ]; then
            echo "Going to upload report history to s3"
            aws s3 cp --quiet --recursive $REPORT_HISTORY_DIR $S3_HISTORY_URL
            echo "HISTORY_UPLOADED=yes" >> $GITHUB_ENV
            echo "History uploaded"
          else
            echo "History folder of report is not found"
            REPORT_DIR_STRUCT=$(ls -lah $REPORT_DIR)
            echo "Report directory structure: $REPORT_DIR_STRUCT"
            echo "HISTORY_UPLOADED=no" >> $GITHUB_ENV
            exit 0
          fi

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              echo Going to upload report to s3
              aws s3 cp --quiet --recursive $REPORT_DIR $S3_FULL_URL
              echo "ARTIFACT_UPLOADED=yes" >> $GITHUB_ENV
              echo Report was uploaded
          else
              echo Reports dir NOT FOUND
              echo "ARTIFACT_UPLOADED=no" >> $GITHUB_ENV
              exit 0
          fi

      - name: Summary
        if: ${{ always() }}
        shell: bash
        run: |
          if [ $ARTIFACT_UPLOADED != 'yes' ]; then
              echo "Allure report was not uploaded"
              echo "Please check logs of previous steps"
          else
            echo "Allure report is ready --> $REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$$BOSS_INTEGRATION/"
            echo "url=$REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$BOSS_INTEGRATION/" >> $GITHUB_OUTPUT
          fi

      - name: Extract stats for email
        id: stats
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              TEST_STATS=$( jq '.statistic' $REPORT_DIR/widgets/summary.json )
              echo Extracted test stats
              echo "${TEST_STATS}"
              PASSED=$( jq '.statistic.passed' $REPORT_DIR/widgets/summary.json )
              echo "${PASSED}"     
              TOTAL=$( jq '.statistic.total' $REPORT_DIR/widgets/summary.json )
              echo "${TOTAL}"          
              PASSRATE=$(awk -v p=$PASSED -v t=$TOTAL 'BEGIN {r=p/t*100; printf "%.2f", r}')
              echo "passrate=$PASSRATE" >> $GITHUB_OUTPUT  
          else
              exit 0
          fi

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  smoke:
    name: Run smoke tests for Finland (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    needs: [ config, api_gateway, boss_integration ]
    if: ${{ always() }}

    env:
      TEST: smoke
      CYCLE: "AMWEIA-C18602"
      EXCLUDE_TEST: "@excluded"
    outputs:
      allure_addr: ${{ steps.summary.outputs.url }}
      passrate: ${{ steps.stats.outputs.passrate }}

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"
          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$TEST"
          S3_HISTORY_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/history/$TEST"
          HISTORY_DIR="./history"
          # Set useful env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV
          echo "HISTORY_DIR=$HISTORY_DIR" >> $GITHUB_ENV
          echo "S3_HISTORY_URL=$S3_HISTORY_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Checkout ${{ env.ACTIONS_REPO }} repo
        uses: actions/checkout@v4
        with:
          path: actions
          token: ${{ secrets.GIT_TOKEN }}
          repository: ${{ env.ACTIONS_REPO }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}

      - name: Maven execution
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -P$TEST -Denv=$ENV \
                            -Dcountry=$COUNTRY \
                            -Dbrowser=$BROWSER \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="@smoke_eu and (@$COUNTRY or @ri1) and not @$EXCLUDE_TEST"

      - name: Copy and filter previously saved history folder to allure results
        if: ${{ always() }}
        working-directory: ${{ env.CODEBASE }}
        shell: bash
        run: |
          mkdir -p $HISTORY_DIR
          aws s3 cp --recursive $S3_HISTORY_URL $HISTORY_DIR
          if [ -z "$(ls -A $HISTORY_DIR)"]; then
            echo "No history found for this workflow"
          else
            mvn -e clean install -Dbrowser="$BROWSER" \
                                 -DfailIfNoTests=false \
                                 -PdataGenerator \
                                 -Dcountry="$COUNTRY" \
                                 -Denv="$ENV" \
                                 -Dtest="$HISTORY_FILTER"
            cp -r "$HISTORY_DIR" "$ARTIFACTS_DIR/history"
          fi

      - name: Generate allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn -B allure:report

      - name: Try to upload history of allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d "$REPORT_HISTORY_DIR" ]; then
            echo "Going to upload report history to s3"
            aws s3 cp --quiet --recursive $REPORT_HISTORY_DIR $S3_HISTORY_URL
            echo "HISTORY_UPLOADED=yes" >> $GITHUB_ENV
            echo "History uploaded"
          else
            echo "History folder of report is not found"
            REPORT_DIR_STRUCT=$(ls -lah $REPORT_DIR)
            echo "Report directory structure: $REPORT_DIR_STRUCT"
            echo "HISTORY_UPLOADED=no" >> $GITHUB_ENV
            exit 0
          fi

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              echo Going to upload report to s3
              aws s3 cp --quiet --recursive $REPORT_DIR $S3_FULL_URL
              echo "ARTIFACT_UPLOADED=yes" >> $GITHUB_ENV
              echo Report was uploaded
          else
              echo Reports dir NOT FOUND
              echo "ARTIFACT_UPLOADED=no" >> $GITHUB_ENV
              exit 0
          fi

      - name: Summary
        if: ${{ always() }}
        id: summary
        shell: bash
        run: |
          if [ $ARTIFACT_UPLOADED != 'yes' ]; then
              echo "Allure report was not uploaded"
              echo "Please check logs of previous steps"
          else
            echo "Allure report is ready --> $REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$TEST/"
            echo "url=$REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$TEST/" >> $GITHUB_OUTPUT
          fi

      - name: Extract stats for email
        id: stats
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              TEST_STATS=$( jq '.statistic' $REPORT_DIR/widgets/summary.json )
              echo Extracted test stats
              echo "${TEST_STATS}"
              PASSED=$( jq '.statistic.passed' $REPORT_DIR/widgets/summary.json )
              echo "${PASSED}"     
              TOTAL=$( jq '.statistic.total' $REPORT_DIR/widgets/summary.json )
              echo "${TOTAL}"         
              PASSRATE=$(awk -v p=$PASSED -v t=$TOTAL 'BEGIN {r=p/t*100; printf "%.2f", r}')
              echo "passrate=$PASSRATE" >> $GITHUB_OUTPUT  
          else
              exit 0
          fi

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  epics_01_05:
    name: Epics 01 and 05 (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 01
      INCLUDE_TEST: "(@Regression_01 or @Regression_05)"
      EXCLUDE_TEST: "@excluded"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  epic_02:
    name: Epic 02 (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 02
      INCLUDE_TEST: "@Regression_02"
      EXCLUDE_TEST: "@excluded"
      CYCLE: "AMWEIA-C18601"


    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf


  epics_03_06:
    name: Epics 03 and 06 (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 03
      INCLUDE_TEST: "(@Regression_03 or @Regression_06)"
      EXCLUDE_TEST: "(@CancelOrder or @excluded)"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf


  epic_040:
    name: Epic 040 (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 04
      INCLUDE_TEST: "(@Regression_04 and @SingleOrder)"
      EXCLUDE_TEST: "(@CancelOrder or @excluded)"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  epics_041_046_047:
    name: Epics 041 and 046 and 047 (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 05
      INCLUDE_TEST: "(@Regression_04 and (@MultiCart or @CopyOrder or @OrderEditAddress))"
      EXCLUDE_TEST: "(@CancelOrder or @excluded)"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf


  epic_045:
    name: Epic 045 (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 06
      INCLUDE_TEST: "(@Regression_04 and @Promo)"
      EXCLUDE_TEST: "(@CancelOrder or @excluded)"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  epic_11_partial:
    name: Epic 11 Partial Return (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 07
      INCLUDE_TEST: "(@Regression_11 and @PartialReturn)"
      EXCLUDE_TEST: "(@excluded or @Long)"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}

      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  epic_11_full:
    name: Epic 11 Full Return (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 08
      INCLUDE_TEST: "(@Regression_11 and @FullReturn)"
      EXCLUDE_TEST: "(@excluded or @Long)"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}

      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  epics_042_gco_11_long:
    name: Epics 042 and 11 Long (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 09
      INCLUDE_TEST: "((@Regression_04 and @Gco) or (@Regression_11 and @Long))"
      EXCLUDE_TEST: "@excluded"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  epics_043_12_15:
    name: Epics 043 and 12 and 15 (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ regression_history, smoke ]
    if: ${{ always() }}

    env:
      JOB_NUM: 10
      INCLUDE_TEST: "((@Regression_04 and @CountrySpecificOrders) or @Regression_12 or @Regression_15)"
      EXCLUDE_TEST: "(@CancelOrder or @excluded)"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -Pregression \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  cancellations:
    name: Tests with order cancel flow (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ epics_01_05, epic_02, epics_03_06, epic_040, epics_041_046_047, epic_045, epic_11_partial, epic_11_full, epics_042_gco_11_long, epics_043_12_15 ]
    if: ${{ always() }}

    env:
      JOB_NUM: 11
      INCLUDE_TEST: "@CancelOrder"
      EXCLUDE_TEST: "@excluded"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -PsingleThread \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  sop:
    name: Tests with SOP flow (t3a.xlarge)
    runs-on: [ self-hosted, t3a.xlarge ]
    timeout-minutes: 180
    needs: [ epics_01_05, epic_02, epics_03_06, epic_040, epics_041_046_047, epic_045, epic_11_partial, epic_11_full, epics_042_gco_11_long, epics_043_12_15 ]
    if: ${{ always() }}

    env:
      JOB_NUM: 12
      INCLUDE_TEST: "@Regression_SOP"
      EXCLUDE_TEST: "(@CancelOrder or @excluded)"
      CYCLE: "AMWEIA-C18601"

    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Maven execute
        shell: bash
        env:
          DISPLAY: ":1.0"
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn clean install -Dbrowser=$BROWSER \
                            -PsingleThread \
                            -Dcountry=$COUNTRY \
                            -Denv=$ENV \
                            -DtestRunId=$TEST_RUN_ID \
                            -Dcycle=$CYCLE \
                            -Dcucumber.filter.tags="$INCLUDE_TEST and (@$COUNTRY or @ri1) and not $EXCLUDE_TEST"

      - name: Try to upload allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          # Try to copy allure report
          if [ -d $ARTIFACTS_DIR ]; then
              mkdir -p allure
              for i in $ARTIFACTS_DIR/*; do cp -rf "$i" allure; done
          else
              echo Reports dir NOT FOUND
              exit 0
          fi

          # Upload allure report to s3
          tar -zcf allure_$JOB_NUM.tar.gz allure
          aws s3 cp  allure_$JOB_NUM.tar.gz  $S3_FULL_URL/allure_$JOB_NUM.tar.gz

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  regression_summary:
    name: Generate results (t3a.medium)
    runs-on: [ self-hosted, t3a.medium ]
    timeout-minutes: 180
    needs: [ epics_01_05, epic_02, epics_03_06, epic_040, epics_041_046_047, epic_045, epic_11_partial, epic_11_full, epics_042_gco_11_long, epics_043_12_15, cancellations, sop ]
    if: ${{ always() }}

    outputs:
      allure_addr: ${{ steps.summary.outputs.url }}
      passrate: ${{ steps.stats.outputs.passrate }}
      passed: ${{ steps.stats.outputs.passed }}
      failed: ${{ steps.stats.outputs.failed }}
      broken: ${{ steps.stats.outputs.broken }}
      skipped: ${{ steps.stats.outputs.skipped }}
      total: ${{ steps.stats.outputs.total }}


    steps:
      - name: Helper step
        shell: bash
        run: |
          ip_addr=$(ip --brief a | tail -n1 | awk '{print $3}')
          echo "Agent IP address is: ${ip_addr%/*}"

          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')
          S3_FULL_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION"
          ALLURE_RESULTS_HISTORY_DIR="b2c_ootb/target/allure-results/history"
          S3_HISTORY_URL="s3://$S3_BUCKET_NAME/$WORKFLOW_NAME/history/$REGRESSION"

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV
          echo "S3_FULL_URL=$S3_FULL_URL" >> $GITHUB_ENV
          echo "ALLURE_RESULTS_HISTORY_DIR=$ALLURE_RESULTS_HISTORY_DIR" >> $GITHUB_ENV
          echo "S3_HISTORY_URL=$S3_HISTORY_URL" >> $GITHUB_ENV

      - name: Checkout AmwayAutoQA repo
        uses: actions/checkout@v4
        with:
          path: ${{ env.CODEBASE }}

      - name: Checkout ${{ env.ACTIONS_REPO }} repo
        uses: actions/checkout@v4
        with:
          path: actions
          token: ${{ secrets.GIT_TOKEN }}
          repository: ${{ env.ACTIONS_REPO }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}


      - name: Download artifacts from the previous steps
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          mkdir -p $ARTIFACTS_DIR
          cd $ARTIFACTS_DIR

          # Copy results for s3 to appropriate dir
          aws s3 cp --quiet --recursive  $S3_FULL_URL .
          for file in *.tar.gz; do
              tar -zxf $file
          done

          for x in allure/*; do mv -- "$x" .; done
          rmdir allure

      - name: Check and copy previously-saved history folder to allure-results
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          cd $ARTIFACTS_DIR
          mkdir history
          aws s3 cp --recursive $S3_HISTORY_URL ./history
          if [ -z "$(ls -A ./history)"]; then
            echo there is NO history FOUND for this workflow
          else
            echo this workflow history is copied
          fi

      - name: Generate allure report
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          mvn allure:report

      - name: Upload prepared allure report to s3
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          aws s3 cp --recursive "$REPORT_DIR" $S3_FULL_URL

      - name: Try to upload history of allure report
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_HISTORY_DIR ]; then
              ls -A $REPORT_HISTORY_DIR
              echo Going to upload report history to s3
              aws s3 cp --quiet --recursive $REPORT_HISTORY_DIR $S3_HISTORY_URL
              echo "HISTORY_UPLOADED=yes" >> $GITHUB_ENV
              echo History was uploaded
          else
              echo History dir of report NOT FOUND
              tmpVar=$(ls $REPORT_DIR)
              echo "Showing Report directory structure: $tmpVar"
              echo "HISTORY_UPLOADED=no" >> $GITHUB_ENV
              exit 0
          fi

      - name: Summary
        id: summary
        shell: bash
        run: |
          echo
          echo "Allure report could be found here: $REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION/"
          echo "url=$REPORT_URL/$WORKFLOW_NAME/N$GITHUB_RUN_NUMBER/$REGRESSION/" >> $GITHUB_OUTPUT
          echo
          echo "history.json could be found here: $REPORT_URL/$WORKFLOW_NAME/history/$REGRESSION/history.json"
          echo "history-trend.json could be found here: $REPORT_URL/$WORKFLOW_NAME/history/$REGRESSION/history-trend.json"
          echo "retry-trend.json could be found here: $REPORT_URL/$WORKFLOW_NAME/history/$REGRESSION/retry-trend.json"
          echo "categories-trend.json could be found here: $REPORT_URL/$WORKFLOW_NAME/history/$REGRESSION/categories-trend.json"

      - name: Extract stats for email
        id: stats
        if: ${{ always() }}
        shell: bash
        working-directory: ${{ env.CODEBASE }}
        run: |
          if [ -d $REPORT_DIR ]; then
              TEST_STATS=$( jq '.statistic' $REPORT_DIR/widgets/summary.json )
              echo Extracted test stats
              echo "${TEST_STATS}"
              PASSED=$( jq '.statistic.passed' $REPORT_DIR/widgets/summary.json )
              echo "passed=$PASSED" >> $GITHUB_OUTPUT
              FAILED=$( jq '.statistic.failed' $REPORT_DIR/widgets/summary.json )
              echo "failed=$FAILED" >> $GITHUB_OUTPUT
              BROKEN=$( jq '.statistic.broken' $REPORT_DIR/widgets/summary.json )
              echo "broken=$BROKEN" >> $GITHUB_OUTPUT
              SKIPPED=$( jq '.statistic.skipped' $REPORT_DIR/widgets/summary.json )
              echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT          
              TOTAL=$( jq '.statistic.total' $REPORT_DIR/widgets/summary.json )
              echo "total=$TOTAL" >> $GITHUB_OUTPUT          
              PASSRATE=$(awk -v p=$PASSED -v t=$TOTAL 'BEGIN {r=p/t*100; printf "%.2f", r}')
              echo "passrate=$PASSRATE" >> $GITHUB_OUTPUT  
          else
              exit 0
          fi

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}

      - name: Clean up
        shell: bash
        if: ${{ always() }}
        run: |
          ls -A | xargs -n 1 rm -rf

  summary:
    name: Show results of the all tests (t3a.small)
    runs-on: [ self-hosted, t3a.small ]
    needs: [ config, api_gateway, boss_integration, smoke, regression_summary ]
    if: ${{ always() }}

    steps:

      - name: Print results of all tests
        shell: bash
        run: |
          CONFIG_OUTPUT=${{ needs.config.outputs.allure_addr }}
          API_GATEWAY_OUTPUT=${{ needs.api_gateway.outputs.allure_addr }}
          BOSS_INTEGRATION_OUTPUT=${{ needs.boss_integration.outputs.allure_addr }}
          SMOKE_OUTPUT=${{ needs.smoke.outputs.allure_addr }}
          REGRESSION_OUTPUT=${{ needs.regression_summary.outputs.allure_addr }}

          echo
          echo "Config smoke: $CONFIG_OUTPUT"
          echo "API gateway endpoints: $API_GATEWAY_OUTPUT"
          echo "BOSS integration endpoints: $BOSS_INTEGRATION_OUTPUT"
          echo "Smoke: $SMOKE_OUTPUT"
          echo "Regression: $REGRESSION_OUTPUT"

      - name: Helper step
        shell: bash
        run: |
          CODEBASE="${GITHUB_REPOSITORY##*/}"
          WORKFLOW_NAME=$(echo ${GITHUB_WORKFLOW,,} | sed -e 's:\s:_:g')

          # Set usefull env vars for next steps
          echo "CODEBASE=$CODEBASE" >> $GITHUB_ENV
          echo "WORKFLOW_NAME=$WORKFLOW_NAME" >> $GITHUB_ENV

      - name: Checkout ${{ env.ACTIONS_REPO }} repo
        uses: actions/checkout@v4
        with:
          path: actions
          token: ${{ secrets.GIT_TOKEN }}
          repository: ${{ env.ACTIONS_REPO }}

      - name: Login into the AWS ECR registry
        shell: bash
        run: |
          aws ecr get-login-password --region  eu-central-1   | docker login --username AWS --password-stdin ${{ env.ECR_REGISTRY }}

      - name: Notify after completion (email media)
        if: ${{ always() }}
        uses: "./actions/send-email"
        with:
          smtp_server: ${{ env.SMTP_SERVER }}
          rcpts: ${{ env.RCPTS}}
          subj: "${{ github.workflow }} #${{ github.run_number}} COMPLETED"
          to: Amway.EU.AQA@Amway.com
          msg: |
            <h1> ${{ github.workflow }} ${{ github.run_number}} COMPLETED</h1>
            <p>Amway Environments Daily status</p?
            <p><a href='https://amway-prod.tt.com.pl/jira/secure/Dashboard.jspa?selectPageId=15721'>Dashboard</a></p>
            <p>Allure Reports:</p>
            <p><a href='${{ env.REPORT_URL }}/${{ env.WORKFLOW_NAME }}/N${{ github.run_number }}/${{ env.CONFIG }}/'>Config smoke</a> (passrate: ${{ needs.config.outputs.passrate }} %)</p>
            <p><a href='${{ env.REPORT_URL }}/${{ env.WORKFLOW_NAME }}/N${{ github.run_number }}/${{ env.API_GATEWAY }}/'>API gateway endpoints</a> (passrate: ${{ needs.api_gateway.outputs.passrate }} %)</p>
            <p><a href='${{ env.REPORT_URL }}/${{ env.WORKFLOW_NAME }}/N${{ github.run_number }}/${{ env.BOSS_INTEGRATION }}/'>BOSS integration endpoints</a> (passrate: ${{ needs.boss_integration.outputs.passrate }} %)</p>
            <p><a href='${{ env.REPORT_URL }}/${{ env.WORKFLOW_NAME }}/N${{ github.run_number }}/${{ env.SMOKE }}/'>Smoke</a> (passrate: ${{ needs.smoke.outputs.passrate }} %)</p>
            <p><a href='${{ env.REPORT_URL }}/${{ env.WORKFLOW_NAME }}/N${{ github.run_number }}/${{ env.REGRESSION }}/'>Regression</a> (passrate: ${{ needs.regression_summary.outputs.passrate }} %)</p>
            <hr><p>Regression test statistics:</p>
            <p><b>Passrate: ${{ needs.regression_summary.outputs.passrate }} %</b></p>
            <p>Passed: ${{ needs.regression_summary.outputs.passed }}</p>
            <p>Failed: ${{ needs.regression_summary.outputs.failed }}</p>
            <p>Broken: ${{ needs.regression_summary.outputs.broken }}</p>
            <p>Skipped: ${{ needs.regression_summary.outputs.skipped }}</p>
            <p>Total: ${{ needs.regression_summary.outputs.total }}</p>

      - name: Logout of Amazon ECR
        if: ${{ always() }}
        run: docker logout ${{ env.ECR_REGISTRY }}
